{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "478de2fe-5c43-4bdf-bda5-45372d9c34ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.cluster import KMeansClusterer\n",
    "import re\n",
    "import random\n",
    "from heapq import nlargest\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b741080-5b6e-49f4-8b3b-116b7ea68645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up notebook to display multiple outputs in one cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35a765fb-ba77-4dde-9e7f-b3725226ac49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jlo's dress! #eredcarpet #goldenglobes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what's making sofia vergara's boobs stay like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anne hathaway has got me living. #goldenglobes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jennifer lopez's lace dress? thoughts? #golden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>podrán criticar a #adele de su moda y su maniq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105785</th>\n",
       "      <td>thank god anne hathaway and hugh jackman won f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105786</th>\n",
       "      <td>ben affleck celebrates his win backstage. #gol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105787</th>\n",
       "      <td>golden globes, lots of fashion messes...but gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105788</th>\n",
       "      <td>did they have mug shots at the golden globes?!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105789</th>\n",
       "      <td>says @benaffleck: \"i also didn't get the actin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105790 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "0                  jlo's dress! #eredcarpet #goldenglobes\n",
       "1       what's making sofia vergara's boobs stay like ...\n",
       "2          anne hathaway has got me living. #goldenglobes\n",
       "3       jennifer lopez's lace dress? thoughts? #golden...\n",
       "4       podrán criticar a #adele de su moda y su maniq...\n",
       "...                                                   ...\n",
       "105785  thank god anne hathaway and hugh jackman won f...\n",
       "105786  ben affleck celebrates his win backstage. #gol...\n",
       "105787  golden globes, lots of fashion messes...but gl...\n",
       "105788  did they have mug shots at the golden globes?!...\n",
       "105789  says @benaffleck: \"i also didn't get the actin...\n",
       "\n",
       "[105790 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in and processing the gg2013 tweets file\n",
    "tweets = pd.read_json('gg2013.json')\n",
    "\n",
    "# Subsetting to tweets that are not retweets\n",
    "no_retweets = []\n",
    "for j in range(0, len(tweets)):\n",
    "    text = tweets.loc[j]['text']\n",
    "    if not re.search(\"^RT\", text):\n",
    "        no_retweets.append(text.lower())\n",
    "\n",
    "no_retweets_df = pd.DataFrame({'text': no_retweets})\n",
    "no_retweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d1c5a80-03f4-4473-8951-2e37dfb960f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['best actor', 'best comedy/musical movie', 'best original score', 'best supporting actor', 'best actor - drama', 'best motion picture', 'best actor in a drama', 'best director', 'best mini - series or tv movie', 'best actress', 'best supporting actress', 'best picture', 'best song', 'best original song', 'best screenplay', 'best motion picture - comedy or musical', 'best comedy', 'best animated feature']\n"
     ]
    }
   ],
   "source": [
    "# Searching tweets for the specified regular expression\n",
    "possible_award_tweets = [] # List of possible tweets mentioning awards\n",
    "hashtags = {} # Dictionary of hashtags used in tweets\n",
    "for j in range(0, len(no_retweets_df)):\n",
    "    text = no_retweets_df.loc[j]['text']\n",
    "    if re.search(\"wins best\", text) or re.search(\"nominated for best\", text):\n",
    "        possible_award_tweets.append(text) # Save a tweet if it contains \"wins best\" or \"nominated for best\"\n",
    "        matches = re.finditer(\"#[a-z0-9]+\\s{1}|#[a-z0-9]+$\", text) # Among the extracted tweets, pull out and save all the unique hashtags\n",
    "        for hashtag in matches:\n",
    "            ht = re.sub(\"#\", \"\", hashtag.group().strip())\n",
    "            if ht not in hashtags:\n",
    "                hashtags[ht] = 1\n",
    "            else:\n",
    "                hashtags[ht] += 1\n",
    "\n",
    "# Keeping the top 10 hashtags\n",
    "hashtags_list = nlargest(10, hashtags, key = hashtags.get)\n",
    "\n",
    "# Extracting all possible words of length 4-20 from the top 10 unique hashtags\n",
    "word_count = 0\n",
    "position_count = 0\n",
    "word_length = 4\n",
    "extracted_word_list = []\n",
    "while word_count < len(hashtags_list):\n",
    "    while word_length <= 20:\n",
    "        while position_count <= len(hashtags_list[word_count]) - word_length:\n",
    "            extracted_word = \"\"\n",
    "            for i in range(0, word_length):\n",
    "                extracted_word += hashtags_list[word_count][position_count + i]\n",
    "            extracted_word_list.append(extracted_word)\n",
    "            position_count += 1\n",
    "        word_length += 1\n",
    "        position_count = 0\n",
    "    word_count += 1\n",
    "    position_count = 0\n",
    "    word_length = 4\n",
    "\n",
    "# Splitting the possible tweets mentioning awards on best, and keeping only the right-hand side\n",
    "possible_award_names = []\n",
    "for award in possible_award_tweets:\n",
    "    split_award = award.split(\"best\")\n",
    "    split_award_rhs = split_award[1]\n",
    "    split_award_rhs = \"best\" + split_award_rhs # Appending 'best' back to the beginning of the right-hand side\n",
    "    # Cleaning up the possible award names by taking some extra stuff out\n",
    "    split_award_rhs = re.sub(\" for .*\", \"\", split_award_rhs) # Deleting everything that falls after the word \"for\", which is usually the winner name\n",
    "    split_award_rhs = re.sub(\"#.*\", \"\", split_award_rhs) # Deleting everything that falls after a hashtag, since these are usually after the award names\n",
    "    split_award_rhs = re.sub(\"@.*\", \"\", split_award_rhs) # Deleting everything that falls after an @\n",
    "    split_award_rhs = re.sub(\"\\.|!.*\", \"\", split_award_rhs) # Deleting everything that falls after a period or exclamation point, since these are after award names\n",
    "    split_award_rhs = re.sub(\" at .*\", \"\", split_award_rhs) # Deleting everything that falls after \"at \", since that is usually followed by the ceremony name\n",
    "    split_award_rhs = re.sub(\"http.*\", \"\", split_award_rhs) # Deleting all web addresses\n",
    "    split_award_rhs = re.sub(\"congrat.*\", \"\", split_award_rhs) # Deleting everything following \"congrats\" or \"congratulations\"\n",
    "    for word in reversed(extracted_word_list): # Deleting all possible words from the top 10 unique hashtags\n",
    "        split_award_rhs = re.sub(word, \"\", split_award_rhs)    \n",
    "    split_award_rhs = re.sub(\",\", \"-\", split_award_rhs) # Changing all commas to dashes\n",
    "    split_award_rhs = re.sub(\"-$\", \"\", split_award_rhs) # Deleting all dashes that end lines\n",
    "    split_award_rhs = re.sub(\"\\\\n\", \"\", split_award_rhs) # Deleting all new line symbols\n",
    "    split_award_rhs = re.sub(r'([a-z])(-)', r'\\g<1> \\g<2>', split_award_rhs) # Adding a space in between a character and dash\n",
    "    split_award_rhs = re.sub(r'(-)([a-z])', r'\\g<1> \\g<2>', split_award_rhs) # Adding a space in between a dash and character\n",
    "    split_award_rhs = re.sub(\" +\", \" \", split_award_rhs) # Changing all multiple spaces to single spaces\n",
    "    split_award_rhs = split_award_rhs.strip() # Deleting leading and trailing spaces\n",
    "    split_award_rhs_list = split_award_rhs.split(\" \") # Splitting the possible awards names into separate words, generating a list of lists\n",
    "    possible_award_names.append(split_award_rhs_list)\n",
    "\n",
    "# Generating word embeddings for each word contained in the possible award names using Word2Vec\n",
    "embeddings = Word2Vec(possible_award_names, min_count = 1)\n",
    "\n",
    "# Defining a function that averages the word embeddings for each word comprising each unique possible award name\n",
    "def create_award_embedding(possible_award, embeddings):\n",
    "    award_embedding = []\n",
    "    award_word_number = 0\n",
    "    for word in possible_award:\n",
    "        if award_word_number == 0:\n",
    "            award_embedding = embeddings.wv[word]\n",
    "        else:\n",
    "            award_embedding = np.add(award_embedding, embeddings.wv[word])\n",
    "        award_word_number += 1\n",
    "    return np.asarray(award_embedding) / award_word_number\n",
    "\n",
    "# Generating the award-level embeddings for each unique possible award name\n",
    "award_embeddings = []\n",
    "for possible_award in possible_award_names:\n",
    "    award_embeddings.append(create_award_embedding(possible_award, embeddings))\n",
    "\n",
    "# Clustering the award-level embeddings into 25 clusters using K-means clustering\n",
    "kmeans = KMeansClusterer(25, distance = nltk.cluster.util.cosine_distance, repeats = 10, avoid_empty_clusters = True)\n",
    "award_clusters = kmeans.cluster(award_embeddings, assign_clusters = True)\n",
    "\n",
    "# Joining together the individual words of the possible award names to generate one phrase per award\n",
    "possible_award_names_clusters = []\n",
    "for award in possible_award_names:\n",
    "    full_award_name = ' '.join(award)\n",
    "    possible_award_names_clusters.append(full_award_name)\n",
    "\n",
    "# Linking in the assigned award clusters to each award name\n",
    "award_clusters_dict = {}\n",
    "for i in range(len(award_clusters)):\n",
    "    if award_clusters[i] not in award_clusters_dict:\n",
    "        award_clusters_dict[award_clusters[i]] = []\n",
    "    if possible_award_names_clusters[i] not in award_clusters_dict[award_clusters[i]]:\n",
    "        award_clusters_dict[award_clusters[i]].append(possible_award_names_clusters[i])\n",
    "\n",
    "# Counting the occurrences of all possible award names\n",
    "possible_award_names_count = {}\n",
    "for award in possible_award_names_clusters:\n",
    "    if award != \"best\": # Possible award string is not only the word \"best\"\n",
    "        if award not in possible_award_names_count:\n",
    "            possible_award_names_count[award] = 1\n",
    "        else:\n",
    "            possible_award_names_count[award] += 1\n",
    "\n",
    "# Selecting the most frequently mentioned possible award name from each cluster, if the possible award name was tweeted at least twice\n",
    "final_awards = []\n",
    "for cluster, award_names in award_clusters_dict.items():\n",
    "    max_tweet_frequency = 1\n",
    "    final_award = \"\"\n",
    "    for award in award_names:\n",
    "        for aw, count in possible_award_names_count.items():\n",
    "            if award == aw and count > max_tweet_frequency:\n",
    "                max_tweet_frequency = count\n",
    "                final_award = award\n",
    "            elif award == aw and count > 1 and count == max_tweet_frequency:\n",
    "                if random.randint(0, 1) == 1:\n",
    "                    final_award = award\n",
    "    final_awards.append(final_award)\n",
    "\n",
    "# Removing empty strings from the list of final award names\n",
    "while \"\" in final_awards:\n",
    "    final_awards.remove(\"\")\n",
    "\n",
    "print(final_awards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c552fa-cca2-4427-b8dc-664e747ecd02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
