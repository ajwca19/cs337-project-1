{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4c6e2ac-8934-4347-b65c-dcc847a1d4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/adenweiser/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing necessary modules - pandas, nltk, regex, spacy, and RNG\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "import re\n",
    "import random\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eae737e9-dc6d-4411-b09d-6729fd64d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up notebook to display multiple outputs in one cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0d87b4a-e2d4-4e97-81e0-65e67bc1489a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JLo's dress!</td>\n",
       "      <td>{'screen_name': 'Dozaaa_xo', 'id': 557374298}</td>\n",
       "      <td>290620657987887104</td>\n",
       "      <td>2013-01-14 00:45:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What's making Sofia Vergara's boobs stay like ...</td>\n",
       "      <td>{'screen_name': 'theAmberShow', 'id': 14648726}</td>\n",
       "      <td>290620657887219713</td>\n",
       "      <td>2013-01-14 00:45:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @FabSugar: Kerry Washington is EVERYTHING. ...</td>\n",
       "      <td>{'screen_name': 'SweetyPW', 'id': 35498686}</td>\n",
       "      <td>290620657828524032</td>\n",
       "      <td>2013-01-14 00:45:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anne Hathaway has got me living.</td>\n",
       "      <td>{'screen_name': '_NicoleEdwards', 'id': 144430...</td>\n",
       "      <td>290620657799159809</td>\n",
       "      <td>2013-01-14 00:45:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jennifer Lopez's lace dress? Thoughts?</td>\n",
       "      <td>{'screen_name': 'lolaogunnaike', 'id': 134953223}</td>\n",
       "      <td>290620657778188288</td>\n",
       "      <td>2013-01-14 00:45:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174638</th>\n",
       "      <td>RT @authorViviAnna: I was sad that Mandy Patin...</td>\n",
       "      <td>{'screen_name': 'dana1204', 'id': 18091543}</td>\n",
       "      <td>290675889379876864</td>\n",
       "      <td>2013-01-14 04:25:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174639</th>\n",
       "      <td>RT @_ItzelMartinez_: Jennifer Lawrence aceptan...</td>\n",
       "      <td>{'screen_name': 'IamTrisEverdeen', 'id': 55126...</td>\n",
       "      <td>290675889128230914</td>\n",
       "      <td>2013-01-14 04:25:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174640</th>\n",
       "      <td>Golden Globes, lots of fashion messes...but gl...</td>\n",
       "      <td>{'screen_name': 'Dpharmakis23', 'id': 852045842}</td>\n",
       "      <td>290675893024747523</td>\n",
       "      <td>2013-01-14 04:25:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174641</th>\n",
       "      <td>Did they have mug shots at the golden globes?!...</td>\n",
       "      <td>{'screen_name': 'reynaramirez22', 'id': 22732662}</td>\n",
       "      <td>290675888763314178</td>\n",
       "      <td>2013-01-14 04:25:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174642</th>\n",
       "      <td>Says @BenAffleck: \"I also didn't get the Actin...</td>\n",
       "      <td>{'screen_name': 'goldenglobes', 'id': 18667907}</td>\n",
       "      <td>290675893494484992</td>\n",
       "      <td>2013-01-14 04:25:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174643 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "0                                          JLo's dress!     \n",
       "1       What's making Sofia Vergara's boobs stay like ...   \n",
       "2       RT @FabSugar: Kerry Washington is EVERYTHING. ...   \n",
       "3                       Anne Hathaway has got me living.    \n",
       "4                 Jennifer Lopez's lace dress? Thoughts?    \n",
       "...                                                   ...   \n",
       "174638  RT @authorViviAnna: I was sad that Mandy Patin...   \n",
       "174639  RT @_ItzelMartinez_: Jennifer Lawrence aceptan...   \n",
       "174640  Golden Globes, lots of fashion messes...but gl...   \n",
       "174641  Did they have mug shots at the golden globes?!...   \n",
       "174642  Says @BenAffleck: \"I also didn't get the Actin...   \n",
       "\n",
       "                                                     user                  id  \\\n",
       "0           {'screen_name': 'Dozaaa_xo', 'id': 557374298}  290620657987887104   \n",
       "1         {'screen_name': 'theAmberShow', 'id': 14648726}  290620657887219713   \n",
       "2             {'screen_name': 'SweetyPW', 'id': 35498686}  290620657828524032   \n",
       "3       {'screen_name': '_NicoleEdwards', 'id': 144430...  290620657799159809   \n",
       "4       {'screen_name': 'lolaogunnaike', 'id': 134953223}  290620657778188288   \n",
       "...                                                   ...                 ...   \n",
       "174638        {'screen_name': 'dana1204', 'id': 18091543}  290675889379876864   \n",
       "174639  {'screen_name': 'IamTrisEverdeen', 'id': 55126...  290675889128230914   \n",
       "174640   {'screen_name': 'Dpharmakis23', 'id': 852045842}  290675893024747523   \n",
       "174641  {'screen_name': 'reynaramirez22', 'id': 22732662}  290675888763314178   \n",
       "174642    {'screen_name': 'goldenglobes', 'id': 18667907}  290675893494484992   \n",
       "\n",
       "              timestamp_ms  \n",
       "0      2013-01-14 00:45:38  \n",
       "1      2013-01-14 00:45:38  \n",
       "2      2013-01-14 00:45:38  \n",
       "3      2013-01-14 00:45:38  \n",
       "4      2013-01-14 00:45:38  \n",
       "...                    ...  \n",
       "174638 2013-01-14 04:25:07  \n",
       "174639 2013-01-14 04:25:07  \n",
       "174640 2013-01-14 04:25:08  \n",
       "174641 2013-01-14 04:25:08  \n",
       "174642 2013-01-14 04:25:08  \n",
       "\n",
       "[174643 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in and processing the gg2013 tweets file\n",
    "tweets = pd.read_json('gg2013.json')\n",
    "\n",
    "#takes in a tweet and removes the retweet and any hyperlinks\n",
    "def clean_tweet(tweet_text):\n",
    "    retweet_re = \"^[rR][tT] @[a-zA-Z0-9_]*: \"\n",
    "    hyperlink_re = \"http://[a-zA-Z0-9./-]*\"\n",
    "    hashtag_re = \"#[a-zA-Z0-9_]+\"\n",
    "    return re.sub(hyperlink_re, \"\", re.sub(hashtag_re, \"\", tweet_text))\n",
    "\n",
    "#read in tweets and make them nice and clean\n",
    "for i in range(0, len(tweets)): \n",
    "    cleaned_tweet = clean_tweet(tweets.loc[i]['text'])\n",
    "    tweets.at[i, 'text'] = cleaned_tweet\n",
    "tweets\n",
    "\n",
    "# Ceremony Name\n",
    "ceremony_name = \"Golden Globes 2013\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6146693-071d-4523-ac91-baad5fd7581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_with_host = [] #list of strings containing the word \"host\", \"hosts\", or \"hosting\"\n",
    "    \n",
    "for i in range(0, len(tweets)):\n",
    "    tweet_text = tweets.loc[i]['text']\n",
    "    if re.search(\"host(s*)\", tweet_text.lower()) and not re.search(\"^[Rr][Tt]\", tweet_text):\n",
    "        tweets_with_host.append(tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16352dc5-93a4-4118-893d-9958ab43e168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAG ENTITIES\n",
    "entities_counts = {} #dictionary with key: entity name and value: number of appearances in tweets\n",
    "entities_clusters = {} #dictionary with key: entity name and value: name of \"representative\" entity\n",
    "parsed_tweets = []\n",
    "for tweet in tweets_with_host:\n",
    "    parsed_tweet = nlp(tweet)\n",
    "    parsed_tweets.append(parsed_tweet)\n",
    "    for entity in parsed_tweet.ents:\n",
    "        if entity.label_ == \"PERSON\" and re.match(\"[a-zA-Z0-9.'’+-_@/]+\", entity.text):\n",
    "            person = entity.text\n",
    "            if person in entities_clusters:\n",
    "                entities_counts[person] += 1\n",
    "            else:\n",
    "                entities_counts[person] = 1\n",
    "                entities_clusters[person] = person\n",
    "#entities_counts\n",
    "\n",
    "entities_to_remove = set()\n",
    "for entity_a in entities_clusters:\n",
    "    #print(\"\\n\\n\\n ENTITY A: \" + entity_a)\n",
    "    for entity_b in entities_clusters:\n",
    "        #print(\"\\n ENTITY B: \" + entity_b + \"\\n_____________\\n\")\n",
    "        if entities_counts[entity_a] >= entities_counts[entity_b]:\n",
    "            #entity a is more popular than entity b\n",
    "            entity_a_tokens = entity_a.split(\" \")\n",
    "            entity_b_tokens = entity_b.split(\" \")\n",
    "            for entity_a_token in entity_a_tokens:\n",
    "                #print(\"entity a token: \" + entity_a_token)\n",
    "                if len(entity_a_token) >= len(entity_b) and re.search(entity_a_token, entity_b):\n",
    "                    #entities are a match! cluster them accordingly\n",
    "                    #print(\"clustering: \" + entity_b + \" in group led by \" + entities_clusters[entity_a] + \"\\n\")\n",
    "                    entities_clusters[entity_b] = entities_clusters[entity_a]\n",
    "                    entities_to_remove.add(entity_b)\n",
    "                    break\n",
    "            for entity_b_token in entity_b_tokens:\n",
    "                #print(\"entity b token:\" + entity_b_token)\n",
    "                if len(entity_b_token) >= len(entity_a) and re.search(entity_b_token, entity_a):\n",
    "                    #entities are a match! cluster them accordingly\n",
    "                    #print(\"clustering: \" + entity_b + \" in group led by \" + entities_clusters[entity_a] + \"\\n\")\n",
    "                    entities_clusters[entity_b] = entities_clusters[entity_a]\n",
    "                    entities_to_remove.add(entity_b)\n",
    "                    break\n",
    "#entities_clusters\n",
    "#entities_to_remove\n",
    "\n",
    "#combine counts in the entity_counts dictionary\n",
    "for non_rep in entities_to_remove:\n",
    "    entities_counts[entities_clusters[non_rep]] += entities_counts.pop(non_rep)\n",
    "\n",
    "#entities_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "92e28cc8-aa30-495b-8430-985c759ce8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hosts are ['Amy Poehler', 'Tina Fey']\n"
     ]
    }
   ],
   "source": [
    "#find out if there is one host or multiple hosts\n",
    "\n",
    "host_as_verb = [] #list of all tweets with host/hosts/hosting as a verb\n",
    "host_as_noun = [] #list of all tweets with host/hosts as a noun\n",
    "host_singular = 0 #count of all tweets implying a single host\n",
    "host_plural = 0 #count of all tweets implying more than one host\n",
    "for tweet in parsed_tweets:\n",
    "    host_index = 0\n",
    "    for token in tweet:\n",
    "        if re.search(\"host\", token.text.lower()):\n",
    "            if token.pos_ == \"VERB\":\n",
    "                host_as_verb.append(tweet)\n",
    "                if token.text.lower() == \"host\":\n",
    "                    host_plural += 1\n",
    "                elif token.text.lower() == \"hosts\":\n",
    "                    host_singular += 1\n",
    "                break\n",
    "            elif token.pos_ == \"NOUN\":\n",
    "                host_as_noun.append(tweet)\n",
    "                if token.text.lower() == \"hosts\":\n",
    "                    host_plural += 1\n",
    "                elif token.text.lower() == \"host\":\n",
    "                    host_singular += 1\n",
    "                break\n",
    "        else:\n",
    "            host_index += 1\n",
    "\n",
    "#host_as_verb\n",
    "#host_as_noun\n",
    "#print(\"one host: \" + str(host_singular) + \"; multiple hosts: \" + str(host_plural) + \"\\n\")\n",
    "\n",
    "if host_singular >= host_plural:\n",
    "    likely_host = \"\"\n",
    "    likely_host_count = 0\n",
    "    for candidate in entities_counts:\n",
    "        if entities_counts[candidate] >= likely_host_count:\n",
    "            likely_host = candidate\n",
    "            likely_host_count = entities_counts[candidate]\n",
    "    print(\"The host is \" + likely_host)\n",
    "else:\n",
    "    vote_distribution = list(entities_counts.values())\n",
    "    average_count = sum(vote_distribution)/len(vote_distribution)\n",
    "    likely_hosts = []\n",
    "    for candidate in entities_counts:\n",
    "        if entities_counts[candidate] >= average_count:\n",
    "            likely_hosts.append(candidate)\n",
    "    likely_hosts = sorted(likely_hosts, key = lambda e : entities_counts[e], reverse = True)\n",
    "    #likely_hosts\n",
    "    for i in range(0, len(likely_hosts) - 1):\n",
    "        if entities_counts[likely_hosts[i + 1]] / entities_counts[likely_hosts[i]] < 0.5:\n",
    "            likely_hosts = likely_hosts[:i+1]\n",
    "            break\n",
    "    print(\"The hosts are \" + str(likely_hosts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96efcc45-9117-4ccb-8c81-9af2d4ca4b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
